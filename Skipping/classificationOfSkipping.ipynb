{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# imprt tree\n",
    "from sklearn import tree\n",
    "# import metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/doorgeven/taken</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/doorgeven/mijn...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/postvak/mijn_d...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/postvak/mijn_b...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/postvak/mijn_b...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174929</th>\n",
       "      <td>55314751</td>\n",
       "      <td>/werk_nl/werknemer/werkmap</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174930</th>\n",
       "      <td>55314751</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/doorgeven/taken</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174931</th>\n",
       "      <td>55314751</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/doorgeven/taken</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174932</th>\n",
       "      <td>55314751</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/doorgeven/taken</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174933</th>\n",
       "      <td>55314751</td>\n",
       "      <td>/werk_nl/werknemer/mijn_werkmap/doorgeven/taken</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7174934 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SessionID                                           Activity  anomaly\n",
       "0               46    /werk_nl/werknemer/mijn_werkmap/doorgeven/taken    False\n",
       "1               46  /werk_nl/werknemer/mijn_werkmap/doorgeven/mijn...    False\n",
       "2               46  /werk_nl/werknemer/mijn_werkmap/postvak/mijn_d...    False\n",
       "3               46  /werk_nl/werknemer/mijn_werkmap/postvak/mijn_b...    False\n",
       "4               46  /werk_nl/werknemer/mijn_werkmap/postvak/mijn_b...    False\n",
       "...            ...                                                ...      ...\n",
       "7174929   55314751                         /werk_nl/werknemer/werkmap    False\n",
       "7174930   55314751    /werk_nl/werknemer/mijn_werkmap/doorgeven/taken    False\n",
       "7174931   55314751    /werk_nl/werknemer/mijn_werkmap/doorgeven/taken    False\n",
       "7174932   55314751    /werk_nl/werknemer/mijn_werkmap/doorgeven/taken    False\n",
       "7174933   55314751    /werk_nl/werknemer/mijn_werkmap/doorgeven/taken    False\n",
       "\n",
       "[7174934 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"./labeled_data/labeled_df.csv\", encoding_errors=\"ignore\", on_bad_lines='skip', sep=\",\", index_col=False,\n",
    "                    usecols=['SessionID','Activity','anomaly'])\n",
    "# df_raw[\"TIMESTAMP\"] = pd.to_datetime(df_raw[\"TIMESTAMP\"], infer_datetime_format=True)\n",
    "# df_raw = df_raw.sort_values(by=[\"SessionID\", \"TIMESTAMP\"]).copy()\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change anomaly == True to 1 and False to 0\n",
    "df_raw[\"anomaly\"] = df_raw[\"anomaly\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of anomalous sessions in the dataset:   355\n",
      "Amount of normal sessions in the dataset:      659915\n",
      "Distribution:                                  0.05379480690695014 %\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique SessionID where anomaly == True\n",
    "count_anomaly_raw = df_raw[df_raw[\"anomaly\"] == 1][\"SessionID\"].nunique()\n",
    "count_normal_raw = df_raw[df_raw[\"anomaly\"] == 0][\"SessionID\"].nunique()\n",
    "print(f'Amount of anomalous sessions in the dataset:   {count_anomaly_raw}' )\n",
    "print(f'Amount of normal sessions in the dataset:      {count_normal_raw}')\n",
    "distribution =  count_anomaly_raw / count_normal_raw \n",
    "print(f'Distribution:                                  {distribution * 100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07576733367176075\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "df_anomaly = df_raw[df_raw[\"anomaly\"] == 1].copy()\n",
    "df_normal = df_raw[df_raw[\"anomaly\"] == 0].copy()\n",
    "nr_of_sessions_used = 50000\n",
    "injection_rate = nr_of_sessions_used / count_normal_raw\n",
    "injection_amount = int(injection_rate * count_anomaly_raw)\n",
    "print(injection_rate)\n",
    "print(injection_amount)\n",
    "# get 20 random sessionIDs from the anomaly dataset\n",
    "anomaly_sessionIDs = df_anomaly[\"SessionID\"].sample(n=injection_amount, random_state=1).tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound: 4466611\n",
      "Upper bound: 4516611\n"
     ]
    }
   ],
   "source": [
    "# pick random int > 0 and < (len(df_raw) - nr_of_sessions_used)\n",
    "lower = np.random.randint(0, len(df_raw) - nr_of_sessions_used)\n",
    "upper = lower + nr_of_sessions_used\n",
    "print(f'Lower bound: {lower}')\n",
    "print(f'Upper bound: {lower + nr_of_sessions_used}')\n",
    "# get a random sample of the sessions\n",
    "# df_ = df_raw[df_raw[\"SessionID\"].isin(df_raw[\"SessionID\"].unique()[:nr_of_sessions_used])].copy()\n",
    "df_ = df_normal[df_normal[\"SessionID\"].isin(df_normal[\"SessionID\"].unique()[:nr_of_sessions_used])].copy()\n",
    "df_ = df_.append(df_anomaly[df_anomaly[\"SessionID\"].isin(anomaly_sessionIDs)], ignore_index=True)\n",
    "# Only use the columns that are needed -> SessionID, Activity, anomaly\n",
    "df_50k = df_[[\"SessionID\", \"Activity\", \"anomaly\"]]\n",
    "\n",
    "\n",
    "# remove the sessions with ID in anomaly_sessionIDs from the df_anomaly dataset\n",
    "df_anomaly = df_anomaly[~df_anomaly[\"SessionID\"].isin(anomaly_sessionIDs)].copy()\n",
    "df_anomaly.to_csv(\"gen_sessions/an.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of anomalous sessions in the sampled dataset:   26\n",
      "Amount of normal sessions in the sampled dataset:      50000\n",
      "Distribution:                                          0.052 %\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique SessionID where anomaly == True\n",
    "count_anomaly = df_50k[df_50k[\"anomaly\"] == 1][\"SessionID\"].nunique()\n",
    "count_normal = df_50k[df_50k[\"anomaly\"] == 0][\"SessionID\"].nunique()\n",
    "print(f'Amount of anomalous sessions in the sampled dataset:   {count_anomaly}')\n",
    "print(f'Amount of normal sessions in the sampled dataset:      {count_normal}')\n",
    "distribution =  count_anomaly / count_normal \n",
    "print(f'Distribution:                                          {distribution * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to encode the activities\n",
    "def encode_activities(_df):\n",
    "    df = _df.copy()\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df)\n",
    "    df= le.transform(df)\n",
    "    return df\n",
    "\n",
    "# function to create a list of al the activities\n",
    "def activities_list(_df):\n",
    "  df = _df.copy()\n",
    "  activities = []\n",
    "  for i in df[\"Activity\"].unique():\n",
    "    activities.append(i)\n",
    "  return activities\n",
    "\n",
    "# function to create a dictionary with the activities as keys and the one hot encoded activities as values\n",
    "def create_dict(l1, l2):\n",
    "  dic = {}\n",
    "  for i in range(len(l1)):\n",
    "    dic[l1[i]] = l2[i]\n",
    "  return dic\n",
    "\n",
    "# function to transform each session into a sequence of activities\n",
    "def transform_session_to_sequence(_df):\n",
    "  df = _df.copy()\n",
    "  df_ses = df.groupby(\"SessionID\")[\"Activity\"].apply(list).reset_index()\n",
    "  # merge the anomaly column\n",
    "  df_ses = df_ses.merge(df[[\"SessionID\", \"anomaly\"]].drop_duplicates(), on=\"SessionID\")\n",
    "  return df_ses\n",
    "\n",
    "# function the create the dataFrame for the model\n",
    "def df_for_model(_df,Activity_col):\n",
    "  df = pd.DataFrame(_df[Activity_col].values.tolist(), index= _df.index)\n",
    "  df_for_model = pd.concat([_df, df], axis=1)\n",
    "  df_for_model = df_for_model.drop(columns=[Activity_col])\n",
    "  df_for_model.fillna(0, inplace=True)\n",
    "  return df_for_model\n",
    "  \n",
    "# function to concat 2 dataframes\n",
    "def concat_df(df_gen ,amount_real,amount_generated,_df1 = df_raw,):\n",
    "  df1 = _df1.copy()\n",
    "  df2 = df_gen\n",
    "  df_raw_filtered = df1[df1[\"SessionID\"].isin(df1[\"SessionID\"].unique()[:amount_real])]\n",
    "  df_gen_anomalies_filtered = df2[df2[\"SessionID\"].isin(df2[\"SessionID\"].unique()[:amount_generated])]\n",
    "  df = pd.concat([df_raw_filtered, df_gen_anomalies_filtered], ignore_index=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lists are the same length\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "# list of all possible activities in df_raw\n",
    "ALL_ACTIVITIES = activities_list(df_raw)\n",
    "ENCODED_ACTIVITIES = encode_activities(ALL_ACTIVITIES)\n",
    "DICT = create_dict(ALL_ACTIVITIES, ENCODED_ACTIVITIES)\n",
    "if len(ALL_ACTIVITIES) == len(ENCODED_ACTIVITIES) == len(DICT):\n",
    "  print(\"All lists are the same length\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stappenplan:\n",
    "\n",
    "1. df -> transform_session_to_sequence\n",
    "2. Transform Activities to encoded Activities\n",
    "3. Transform the list in the Activity column to multiple columns with fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = transform_session_to_sequence(df_50k)\n",
    "# base_an = transform_session_to_sequence(df_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data['Activity'] = base_data['Activity'].apply(lambda x: [DICT[i] for i in x])\n",
    "# base_an['Activity'] = base_an['Activity'].apply(lambda x: [DICT[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = df_for_model(base_data, \"Activity\")\n",
    "# base_an = df_for_model(base_an, \"Activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomaly</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>371.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>372.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50021</th>\n",
       "      <td>1</td>\n",
       "      <td>402</td>\n",
       "      <td>402.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50022</th>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>365.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50023</th>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50024</th>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>391.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50025</th>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>393.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50026 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       anomaly    0      1      2      3      4      5      6      7      8  \\\n",
       "0            0  372  371.0  392.0  391.0  391.0  391.0    0.0    0.0    0.0   \n",
       "1            0  369    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2            0  391  372.0  401.0  391.0  391.0  391.0  391.0  369.0  367.0   \n",
       "3            0  372  372.0  372.0  372.0  372.0  372.0    0.0    0.0    0.0   \n",
       "4            0  391  391.0  391.0  391.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "50021        1  402  402.0  402.0  402.0  402.0  402.0  165.0  367.0  622.0   \n",
       "50022        1  367  365.0  398.0  365.0  365.0  398.0  398.0  398.0  398.0   \n",
       "50023        1  353   41.0   41.0  367.0   41.0   41.0   41.0   41.0   41.0   \n",
       "50024        1  367  391.0  392.0  392.0  372.0  372.0  372.0  371.0  371.0   \n",
       "50025        1  367  393.0  393.0  393.0  393.0  393.0  393.0  393.0  393.0   \n",
       "\n",
       "       ...  355  356  357  358  359  360  361  362  363  364  \n",
       "0      ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "50021  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50022  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50023  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50024  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "50025  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[50026 rows x 366 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data\n",
    "# drop the SessionID column\n",
    "base_data = base_data.drop(columns=[\"SessionID\"])\n",
    "base_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [372, 371.0, 392.0, 391.0, 391.0, 391.0, 0.0, ...\n",
       "1        [369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2        [391, 372.0, 401.0, 391.0, 391.0, 391.0, 391.0...\n",
       "3        [372, 372.0, 372.0, 372.0, 372.0, 372.0, 0.0, ...\n",
       "4        [391, 391.0, 391.0, 391.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "                               ...                        \n",
       "50021    [402, 402.0, 402.0, 402.0, 402.0, 402.0, 165.0...\n",
       "50022    [367, 365.0, 398.0, 365.0, 365.0, 398.0, 398.0...\n",
       "50023    [353, 41.0, 41.0, 367.0, 41.0, 41.0, 41.0, 41....\n",
       "50024    [367, 391.0, 392.0, 392.0, 372.0, 372.0, 372.0...\n",
       "50025    [367, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0...\n",
       "Name: seq, Length: 50026, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of the values in column 0 to n of base_data and put in column seq\n",
    "base_data['seq'] = base_data.values.tolist()\n",
    "# drop the first value of the list in seq\n",
    "base_data['seq'] = base_data['seq'].apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the data into train and test data\n",
    "def split_data(_df):\n",
    "  df = _df.copy()\n",
    "  X = df.drop(columns=[\"anomaly\"])\n",
    "  y = df[\"anomaly\"]\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base test and train data\n",
    "X_train, X_test, y_train, y_test = split_data(base_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the generated sessions:\n",
    "base_path = \"gen_sessions/\"\n",
    "gen_sessions_paths = [\n",
    "  # base_path + '5_1000.csv',\n",
    "  # base_path + '10_1000.csv',\n",
    "  # base_path + '25_1000.csv',\n",
    "  # base_path + '50_1000.csv',\n",
    "  # base_path + '75_1000.csv',\n",
    "  # base_path + '100_1000.csv',\n",
    "  base_path + 'an.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score_dicts = {}\n",
    "dict_prec_and_rec_list = {}\n",
    "\n",
    "amount_anomalies_list_total = []\n",
    "precision_score_list_total = []\n",
    "recall_score_list_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_sessions/an.csv\n",
      "10\n",
      "0.9985008994603238\n",
      "0.4995000499950005\n",
      "\n",
      "gen_sessions/an.csv\n",
      "20\n",
      "0.9976014391365181\n",
      "0.599000099990001\n",
      "\n",
      "gen_sessions/an.csv\n",
      "50\n",
      "0.9977013791724965\n",
      "0.599050094990501\n",
      "\n",
      "gen_sessions/an.csv\n",
      "65\n",
      "0.997101738956626\n",
      "0.4988001199880012\n",
      "\n",
      "gen_sessions/an.csv\n",
      "100\n",
      "0.9972016789926045\n",
      "0.4988501149885011\n",
      "\n",
      "gen_sessions/an.csv\n",
      "200\n",
      "0.994203477913252\n",
      "0.5973002699730027\n",
      "\n",
      "gen_sessions/an.csv\n",
      "300\n",
      "0.9938037177693384\n",
      "0.597100289971003\n",
      "\n",
      "gen_sessions/an.csv\n",
      "400\n",
      "0.9916050369778133\n",
      "0.596000399960004\n",
      "\n",
      "gen_sessions/an.csv\n",
      "500\n",
      "0.9917049770137917\n",
      "0.5960503949605039\n",
      "\n",
      "gen_sessions/an.csv\n",
      "600\n",
      "0.9906056366180291\n",
      "0.6954504549545046\n",
      "\n",
      "gen_sessions/an.csv\n",
      "700\n",
      "0.9909054567259644\n",
      "0.5956504349565044\n",
      "\n",
      "gen_sessions/an.csv\n",
      "800\n",
      "0.9915050969418349\n",
      "0.595950404959504\n",
      "\n",
      "gen_sessions/an.csv\n",
      "900\n",
      "0.9912052768338997\n",
      "0.6957504249575043\n",
      "\n",
      "gen_sessions/an.csv\n",
      "1000\n",
      "0.991305216869878\n",
      "0.5958504149585041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "for sessions in gen_sessions_paths:\n",
    "    amount_anomalies_list = []\n",
    "    precision_score_list = []\n",
    "    recall_score_list = []\n",
    "    \n",
    "    # build the dataFrame\n",
    "    cvs = pd.read_csv(sessions,index_col=False)\n",
    "    # check if column Unnamed: 0 exists\n",
    "    if \"Unnamed: 0\" in cvs.columns : cvs = cvs.drop(columns=[\"Unnamed: 0\"])\n",
    "    cvs['anomaly'] = 1\n",
    "    cvs.rename(columns={'URL_FILE':'Activity'}, inplace=True)\n",
    "    gen_df_seq = transform_session_to_sequence(cvs)\n",
    "    \n",
    "    gen_df_seq['Activity'] = gen_df_seq['Activity'].apply(lambda x: [DICT[i] for i in x])\n",
    "    ready_df = df_for_model(gen_df_seq, \"Activity\")\n",
    "    ready_df = ready_df.drop(columns=[\"SessionID\"])\n",
    "    ready_df = ready_df.sample(frac=1).reset_index(drop=True) \n",
    "    \n",
    "    for amount_gen in [10, 20, 50, 65, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "    # from 0 to 250 with a step of 25\n",
    "    # for amount_gen in [0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250]:\n",
    "        amount_real = 0\n",
    "        df_gen = ready_df[:amount_gen]\n",
    "        # print(df_gen)\n",
    "        # Add the generated anomalies to the training dataset\n",
    "        X_train_extra = pd.concat([X_train, df_gen.drop(columns=[\"anomaly\"])]).fillna(0)\n",
    "        y_train_extra = pd.concat([y_train, df_gen[\"anomaly\"]])\n",
    "        \n",
    "        clf = tree.DecisionTreeClassifier().fit(X_train_extra, y_train_extra)\n",
    "        # clf_extra = LogisticRegression(random_state=0, max_iter=1000).fit(X_train_extra, y_train_extra_transformed)\n",
    "        #y_train_predict = clf_extra.predict(X_train_extra)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        print(sessions)\n",
    "        print(amount_gen)\n",
    "        print(accuracy_score(y_test, predictions))\n",
    "        print(balanced_accuracy_score(y_test, predictions))\n",
    "        print()\n",
    "    \n",
    "       \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
